{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "DATAPATH = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSA_ID</th>\n",
       "      <th>Salt</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Target</th>\n",
       "      <th>Target % activity</th>\n",
       "      <th>SMILES_parent</th>\n",
       "      <th>Img</th>\n",
       "      <th>Name</th>\n",
       "      <th>InChiKey</th>\n",
       "      <th>VendorID/ LabNotebook ID/Other Code</th>\n",
       "      <th>...</th>\n",
       "      <th>CompTox</th>\n",
       "      <th>Lipidmaps</th>\n",
       "      <th>DrugCentral</th>\n",
       "      <th>Carotenoid</th>\n",
       "      <th>Metabolights</th>\n",
       "      <th>Brenda</th>\n",
       "      <th>rhea</th>\n",
       "      <th>chemicalbook</th>\n",
       "      <th>swisslipids</th>\n",
       "      <th>gsrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OSA_000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MurD</td>\n",
       "      <td>79.6</td>\n",
       "      <td>CN1CCN(CC1)c1ccc(cc1)C#N</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>4-(4-methylpiperazin-1-yl)benzonitrile</td>\n",
       "      <td>ZSDPKKGOSKXEHN-UHFFFAOYSA-N</td>\n",
       "      <td>Z2856434840</td>\n",
       "      <td>...</td>\n",
       "      <td>DTXSID30354088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OSA_000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MurD</td>\n",
       "      <td>128</td>\n",
       "      <td>CN1CCN(CC1)C(=O)NC1=CC=C(F)C=C1</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>N-(4-fluorophenyl)-4-methylpiperazine-1-carbox...</td>\n",
       "      <td>MDBPFVSVLGYVCQ-UHFFFAOYSA-N</td>\n",
       "      <td>Z2856434944</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OSA_000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MurD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC(CO)(CO)NC(=O)Nc1ccccc1</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>3-(1,3-dihydroxy-2-methylpropan-2-yl)-1-phenyl...</td>\n",
       "      <td>NLGYHTMGWVQQIL-UHFFFAOYSA-N</td>\n",
       "      <td>Z57472297</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OSA_000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MurD</td>\n",
       "      <td>72.4</td>\n",
       "      <td>CC(C(Nc1cc(C#N)ccc1)=O)C</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>N-(3-cyanophenyl)-2-methylpropanamide</td>\n",
       "      <td>JWBISRKEEZGPFB-UHFFFAOYSA-N</td>\n",
       "      <td>Z26548083</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OSA_000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MurE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O=S1(CCN(CC1)Cc2ccc(C)cc2)=O</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>4-(4-methylbenzyl)thiomorpholine 1,1-dioxide</td>\n",
       "      <td>PBEMXBVPRZGFNM-UHFFFAOYSA-N</td>\n",
       "      <td>Z2856434929</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OSA_ID Salt  Batch Target Target % activity  \\\n",
       "0  OSA_000001  NaN    NaN   MurD              79.6   \n",
       "1  OSA_000002  NaN    NaN   MurD               128   \n",
       "2  OSA_000003  NaN    NaN   MurD               NaN   \n",
       "3  OSA_000004  NaN    NaN   MurD              72.4   \n",
       "4  OSA_000005  NaN    NaN   MurE               NaN   \n",
       "\n",
       "                     SMILES_parent     Img  \\\n",
       "0         CN1CCN(CC1)c1ccc(cc1)C#N  #NAME?   \n",
       "1  CN1CCN(CC1)C(=O)NC1=CC=C(F)C=C1  #NAME?   \n",
       "2        CC(CO)(CO)NC(=O)Nc1ccccc1  #NAME?   \n",
       "3         CC(C(Nc1cc(C#N)ccc1)=O)C  #NAME?   \n",
       "4     O=S1(CCN(CC1)Cc2ccc(C)cc2)=O  #NAME?   \n",
       "\n",
       "                                                Name  \\\n",
       "0             4-(4-methylpiperazin-1-yl)benzonitrile   \n",
       "1  N-(4-fluorophenyl)-4-methylpiperazine-1-carbox...   \n",
       "2  3-(1,3-dihydroxy-2-methylpropan-2-yl)-1-phenyl...   \n",
       "3              N-(3-cyanophenyl)-2-methylpropanamide   \n",
       "4       4-(4-methylbenzyl)thiomorpholine 1,1-dioxide   \n",
       "\n",
       "                      InChiKey VendorID/ LabNotebook ID/Other Code  ...  \\\n",
       "0  ZSDPKKGOSKXEHN-UHFFFAOYSA-N                         Z2856434840  ...   \n",
       "1  MDBPFVSVLGYVCQ-UHFFFAOYSA-N                         Z2856434944  ...   \n",
       "2  NLGYHTMGWVQQIL-UHFFFAOYSA-N                           Z57472297  ...   \n",
       "3  JWBISRKEEZGPFB-UHFFFAOYSA-N                           Z26548083  ...   \n",
       "4  PBEMXBVPRZGFNM-UHFFFAOYSA-N                         Z2856434929  ...   \n",
       "\n",
       "          CompTox Lipidmaps DrugCentral Carotenoid  Metabolights Brenda rhea  \\\n",
       "0  DTXSID30354088       NaN         NaN         NaN          NaN    NaN  NaN   \n",
       "1             NaN       NaN         NaN         NaN          NaN    NaN  NaN   \n",
       "2             NaN       NaN         NaN         NaN          NaN    NaN  NaN   \n",
       "3             NaN       NaN         NaN         NaN          NaN    NaN  NaN   \n",
       "4             NaN       NaN         NaN         NaN          NaN    NaN  NaN   \n",
       "\n",
       "  chemicalbook swisslipids  gsrs  \n",
       "0          NaN         NaN   NaN  \n",
       "1          NaN         NaN   NaN  \n",
       "2          NaN         NaN   NaN  \n",
       "3          NaN         NaN   NaN  \n",
       "4          NaN         NaN   NaN  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATAPATH, \"OSAMasterList.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"OSA_ID\",\"Target % activity\", \"SMILES_parent\" ]]\n",
    "df.rename({\"OSA_ID\":\"ID\", \"Target % activity\":\"activity\", \"SMILES_parent\":\"SMILES\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"activity\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = df[\"activity\"].tolist()\n",
    "df[\"activity\"] = df[\"activity\"].apply(lambda x: float(x.split(\" &\")[0]))\n",
    "df = df[df[\"activity\"]>=0] #eliminate negative values as errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_act = []\n",
    "for i in df[\"activity\"].tolist():\n",
    "    if i > 20:\n",
    "        bin = 0\n",
    "    else:\n",
    "        bin = 1\n",
    "    bin_act += [bin]\n",
    "df[\"bin_act\"]=bin_act\n",
    "\n",
    "print(len(df[df[\"bin_act\"]==1]))\n",
    "print(len(df[df[\"bin_act\"]==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DATAPATH, \"murD_inhibition.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 06-12 11:51:16] {2365} INFO - task = classification\n",
      "[flaml.automl: 06-12 11:51:16] {2367} INFO - Data split method: stratified\n",
      "[flaml.automl: 06-12 11:51:16] {2371} INFO - Evaluation method: cv\n",
      "[flaml.automl: 06-12 11:51:16] {1195} INFO - class 1 augmented from 12 to 24\n",
      "[flaml.automl: 06-12 11:51:16] {2448} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 06-12 11:51:16] {2561} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl: 06-12 11:51:16] {2853} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:16] {2984} INFO - Estimated sufficient time budget=3101s. Estimated necessary time budget=71s.\n",
      "[flaml.automl: 06-12 11:51:16] {3036} INFO -  at 0.3s,\testimator lgbm's best error=0.2386,\tbest estimator lgbm's best error=0.2386\n",
      "[flaml.automl: 06-12 11:51:16] {2853} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:16] {3036} INFO -  at 0.5s,\testimator lgbm's best error=0.2386,\tbest estimator lgbm's best error=0.2386\n",
      "[flaml.automl: 06-12 11:51:16] {2853} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:16] {3036} INFO -  at 0.7s,\testimator lgbm's best error=0.2386,\tbest estimator lgbm's best error=0.2386\n",
      "[flaml.automl: 06-12 11:51:16] {2853} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:16] {3036} INFO -  at 0.9s,\testimator lgbm's best error=0.2128,\tbest estimator lgbm's best error=0.2128\n",
      "[flaml.automl: 06-12 11:51:16] {2853} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:17] {3036} INFO -  at 1.1s,\testimator xgboost's best error=0.2522,\tbest estimator lgbm's best error=0.2128\n",
      "[flaml.automl: 06-12 11:51:17] {2853} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:17] {3036} INFO -  at 1.4s,\testimator xgboost's best error=0.2122,\tbest estimator xgboost's best error=0.2122\n",
      "[flaml.automl: 06-12 11:51:17] {2853} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:17] {3036} INFO -  at 1.7s,\testimator lgbm's best error=0.1892,\tbest estimator lgbm's best error=0.1892\n",
      "[flaml.automl: 06-12 11:51:17] {2853} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:17] {3036} INFO -  at 1.9s,\testimator lgbm's best error=0.1892,\tbest estimator lgbm's best error=0.1892\n",
      "[flaml.automl: 06-12 11:51:17] {2853} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:18] {3036} INFO -  at 2.1s,\testimator lgbm's best error=0.1892,\tbest estimator lgbm's best error=0.1892\n",
      "[flaml.automl: 06-12 11:51:18] {2853} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:18] {3036} INFO -  at 2.5s,\testimator lgbm's best error=0.1892,\tbest estimator lgbm's best error=0.1892\n",
      "[flaml.automl: 06-12 11:51:18] {2853} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:18] {3036} INFO -  at 2.7s,\testimator xgboost's best error=0.2122,\tbest estimator lgbm's best error=0.1892\n",
      "[flaml.automl: 06-12 11:51:18] {2853} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:19] {3036} INFO -  at 3.1s,\testimator xgboost's best error=0.2122,\tbest estimator lgbm's best error=0.1892\n",
      "[flaml.automl: 06-12 11:51:19] {2853} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:20] {3036} INFO -  at 4.4s,\testimator extra_tree's best error=0.3422,\tbest estimator lgbm's best error=0.1892\n",
      "[flaml.automl: 06-12 11:51:20] {2853} INFO - iteration 13, current learner rf\n",
      "[flaml.automl: 06-12 11:51:21] {3036} INFO -  at 5.7s,\testimator rf's best error=0.2581,\tbest estimator lgbm's best error=0.1892\n",
      "[flaml.automl: 06-12 11:51:21] {2853} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 06-12 11:51:22] {3036} INFO -  at 6.9s,\testimator rf's best error=0.1878,\tbest estimator rf's best error=0.1878\n",
      "[flaml.automl: 06-12 11:51:22] {2853} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:23] {3036} INFO -  at 7.3s,\testimator xgboost's best error=0.1478,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:23] {2853} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 06-12 11:51:24] {3036} INFO -  at 8.6s,\testimator rf's best error=0.1878,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:24] {2853} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:25] {3036} INFO -  at 9.9s,\testimator extra_tree's best error=0.2644,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:25] {2853} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:25] {3036} INFO -  at 10.0s,\testimator lgbm's best error=0.1808,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:25] {2853} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:26] {3036} INFO -  at 10.4s,\testimator xgboost's best error=0.1478,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:26] {2853} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:26] {3036} INFO -  at 10.8s,\testimator xgboost's best error=0.1478,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:26] {2853} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:27] {3036} INFO -  at 11.0s,\testimator xgboost's best error=0.1478,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:27] {2853} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 06-12 11:51:28] {3036} INFO -  at 12.5s,\testimator rf's best error=0.1878,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:28] {2853} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 06-12 11:51:29] {3036} INFO -  at 13.7s,\testimator rf's best error=0.1878,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:29] {2853} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:30] {3036} INFO -  at 14.0s,\testimator xgboost's best error=0.1478,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:30] {2853} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:31] {3036} INFO -  at 15.3s,\testimator extra_tree's best error=0.2644,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:31] {2853} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:31] {3036} INFO -  at 15.8s,\testimator xgboost's best error=0.1478,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:31] {2853} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:32] {3036} INFO -  at 16.2s,\testimator xgboost's best error=0.1478,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:32] {2853} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:33] {3036} INFO -  at 17.5s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:33] {2853} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:34] {3036} INFO -  at 18.7s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:34] {2853} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:35] {3036} INFO -  at 19.9s,\testimator lgbm's best error=0.1808,\tbest estimator xgboost's best error=0.1478\n",
      "[flaml.automl: 06-12 11:51:35] {2853} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:37] {3036} INFO -  at 21.7s,\testimator lgbm's best error=0.1431,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:37] {2853} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:37] {3036} INFO -  at 21.8s,\testimator lgbm's best error=0.1431,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:37] {2853} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:39] {3036} INFO -  at 23.2s,\testimator extra_tree's best error=0.2003,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:39] {2853} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:39] {3036} INFO -  at 24.0s,\testimator lgbm's best error=0.1431,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:39] {2853} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 06-12 11:51:41] {3036} INFO -  at 25.3s,\testimator rf's best error=0.1878,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:41] {2853} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:42] {3036} INFO -  at 26.6s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:42] {2853} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:43] {3036} INFO -  at 27.6s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:43] {2853} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:44] {3036} INFO -  at 28.1s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:44] {2853} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:44] {3036} INFO -  at 28.5s,\testimator lgbm's best error=0.1431,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:44] {2853} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:44] {3036} INFO -  at 28.7s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:44] {2853} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:46] {3036} INFO -  at 30.1s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.1431\n",
      "[flaml.automl: 06-12 11:51:46] {2853} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:46] {3036} INFO -  at 30.3s,\testimator lgbm's best error=0.1425,\tbest estimator lgbm's best error=0.1425\n",
      "[flaml.automl: 06-12 11:51:46] {2853} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:47] {3036} INFO -  at 31.5s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1425\n",
      "[flaml.automl: 06-12 11:51:47] {2853} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:48] {3036} INFO -  at 32.7s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.1425\n",
      "[flaml.automl: 06-12 11:51:48] {2853} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:48] {3036} INFO -  at 32.9s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1425\n",
      "[flaml.automl: 06-12 11:51:48] {2853} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:49] {3036} INFO -  at 33.2s,\testimator lgbm's best error=0.1425,\tbest estimator lgbm's best error=0.1425\n",
      "[flaml.automl: 06-12 11:51:49] {2853} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:51:50] {3036} INFO -  at 34.4s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.1425\n",
      "[flaml.automl: 06-12 11:51:50] {2853} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:50] {3036} INFO -  at 34.8s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:50] {2853} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:51] {3036} INFO -  at 35.4s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:51] {2853} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:51] {3036} INFO -  at 36.0s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:51] {2853} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:52] {3036} INFO -  at 36.1s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:52] {2853} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:52] {3036} INFO -  at 36.3s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:52] {2853} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:52] {3036} INFO -  at 36.7s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:52] {2853} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:53] {3036} INFO -  at 37.0s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:53] {2853} INFO - iteration 55, current learner rf\n",
      "[flaml.automl: 06-12 11:51:54] {3036} INFO -  at 38.3s,\testimator rf's best error=0.1878,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:54] {2853} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:54] {3036} INFO -  at 38.4s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:54] {2853} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:54] {3036} INFO -  at 38.5s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:54] {2853} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:54] {3036} INFO -  at 38.9s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:54] {2853} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:56] {3036} INFO -  at 40.1s,\testimator lgbm's best error=0.1161,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:56] {2853} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:57] {3036} INFO -  at 41.7s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1161\n",
      "[flaml.automl: 06-12 11:51:57] {2853} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:58] {3036} INFO -  at 43.0s,\testimator lgbm's best error=0.1100,\tbest estimator lgbm's best error=0.1100\n",
      "[flaml.automl: 06-12 11:51:58] {2853} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:59] {3036} INFO -  at 43.3s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1100\n",
      "[flaml.automl: 06-12 11:51:59] {2853} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl: 06-12 11:51:59] {3036} INFO -  at 43.8s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1100\n",
      "[flaml.automl: 06-12 11:51:59] {2853} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl: 06-12 11:51:59] {3036} INFO -  at 43.9s,\testimator lgbm's best error=0.1100,\tbest estimator lgbm's best error=0.1100\n",
      "[flaml.automl: 06-12 11:51:59] {2853} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:00] {3036} INFO -  at 44.3s,\testimator lgbm's best error=0.1100,\tbest estimator lgbm's best error=0.1100\n",
      "[flaml.automl: 06-12 11:52:00] {2853} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:01] {3036} INFO -  at 46.0s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.1100\n",
      "[flaml.automl: 06-12 11:52:01] {2853} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:02] {3036} INFO -  at 46.9s,\testimator lgbm's best error=0.1100,\tbest estimator lgbm's best error=0.1100\n",
      "[flaml.automl: 06-12 11:52:02] {2853} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:03] {3036} INFO -  at 47.1s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 06-12 11:52:03] {2853} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:03] {3036} INFO -  at 47.2s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 06-12 11:52:03] {2853} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:03] {3036} INFO -  at 47.4s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 06-12 11:52:03] {2853} INFO - iteration 71, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:03] {3036} INFO -  at 47.8s,\testimator lgbm's best error=0.0883,\tbest estimator lgbm's best error=0.0883\n",
      "[flaml.automl: 06-12 11:52:03] {2853} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:04] {3036} INFO -  at 48.0s,\testimator xgboost's best error=0.1478,\tbest estimator lgbm's best error=0.0883\n",
      "[flaml.automl: 06-12 11:52:04] {2853} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:04] {3036} INFO -  at 48.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:04] {2853} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:04] {3036} INFO -  at 48.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:04] {2853} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:04] {3036} INFO -  at 48.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:04] {2853} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:04] {3036} INFO -  at 48.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:04] {2853} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:04] {3036} INFO -  at 48.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:04] {2853} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:05] {3036} INFO -  at 49.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:05] {2853} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:05] {3036} INFO -  at 49.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:05] {2853} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:06] {3036} INFO -  at 50.8s,\testimator xgboost's best error=0.1303,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:06] {2853} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:06] {3036} INFO -  at 50.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:06] {2853} INFO - iteration 82, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:07] {3036} INFO -  at 51.1s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:07] {2853} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:07] {3036} INFO -  at 51.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:07] {2853} INFO - iteration 84, current learner rf\n",
      "[flaml.automl: 06-12 11:52:08] {3036} INFO -  at 52.7s,\testimator rf's best error=0.1878,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:08] {2853} INFO - iteration 85, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:09] {3036} INFO -  at 53.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:09] {2853} INFO - iteration 86, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:09] {3036} INFO -  at 53.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:09] {2853} INFO - iteration 87, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:09] {3036} INFO -  at 53.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:09] {2853} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:10] {3036} INFO -  at 54.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:10] {2853} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:10] {3036} INFO -  at 54.7s,\testimator xgboost's best error=0.1303,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:10] {2853} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:10] {3036} INFO -  at 54.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:10] {2853} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:12] {3036} INFO -  at 56.1s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:12] {2853} INFO - iteration 92, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:12] {3036} INFO -  at 56.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:12] {2853} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:12] {3036} INFO -  at 56.7s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:12] {2853} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:12] {3036} INFO -  at 56.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:12] {2853} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:14] {3036} INFO -  at 58.0s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:14] {2853} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:14] {3036} INFO -  at 58.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:14] {2853} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:14] {3036} INFO -  at 58.7s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:14] {2853} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:14] {3036} INFO -  at 58.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:14] {2853} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:15] {3036} INFO -  at 59.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:15] {2853} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:16] {3036} INFO -  at 60.6s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:16] {2853} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:16] {3036} INFO -  at 60.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:16] {2853} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:17] {3036} INFO -  at 61.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:17] {2853} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:17] {3036} INFO -  at 62.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:17] {2853} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:18] {3036} INFO -  at 62.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:18] {2853} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:18] {3036} INFO -  at 62.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:18] {2853} INFO - iteration 106, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:19] {3036} INFO -  at 63.6s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:19] {2853} INFO - iteration 107, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:19] {3036} INFO -  at 63.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:19] {2853} INFO - iteration 108, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:21] {3036} INFO -  at 65.1s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:21] {2853} INFO - iteration 109, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:21] {3036} INFO -  at 65.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:21] {2853} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:21] {3036} INFO -  at 65.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:21] {2853} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:22] {3036} INFO -  at 66.7s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:22] {2853} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:22] {3036} INFO -  at 66.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:22] {2853} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:24] {3036} INFO -  at 68.3s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:24] {2853} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:24] {3036} INFO -  at 68.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:24] {2853} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:24] {3036} INFO -  at 68.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:24] {2853} INFO - iteration 116, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:25] {3036} INFO -  at 69.8s,\testimator extra_tree's best error=0.1439,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:25] {2853} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:25] {3036} INFO -  at 69.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:25] {2853} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:26] {3036} INFO -  at 70.1s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:26] {2853} INFO - iteration 119, current learner rf\n",
      "[flaml.automl: 06-12 11:52:27] {3036} INFO -  at 71.3s,\testimator rf's best error=0.1878,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:27] {2853} INFO - iteration 120, current learner rf\n",
      "[flaml.automl: 06-12 11:52:28] {3036} INFO -  at 72.5s,\testimator rf's best error=0.1878,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:28] {2853} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:29] {3036} INFO -  at 73.9s,\testimator extra_tree's best error=0.1361,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:29] {2853} INFO - iteration 122, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:30] {3036} INFO -  at 74.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:30] {2853} INFO - iteration 123, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:30] {3036} INFO -  at 74.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:30] {2853} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:31] {3036} INFO -  at 75.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:31] {2853} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:31] {3036} INFO -  at 75.7s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:31] {2853} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:32] {3036} INFO -  at 76.1s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:32] {2853} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:32] {3036} INFO -  at 76.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:32] {2853} INFO - iteration 128, current learner rf\n",
      "[flaml.automl: 06-12 11:52:33] {3036} INFO -  at 77.6s,\testimator rf's best error=0.1861,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:33] {2853} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:33] {3036} INFO -  at 77.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:33] {2853} INFO - iteration 130, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:33] {3036} INFO -  at 78.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:33] {2853} INFO - iteration 131, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:34] {3036} INFO -  at 78.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:34] {2853} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:34] {3036} INFO -  at 78.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:34] {2853} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:34] {3036} INFO -  at 78.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:34] {2853} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:35] {3036} INFO -  at 79.1s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:35] {2853} INFO - iteration 135, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:35] {3036} INFO -  at 79.5s,\testimator xgboost's best error=0.1275,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:35] {2853} INFO - iteration 136, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:35] {3036} INFO -  at 79.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:35] {2853} INFO - iteration 137, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:36] {3036} INFO -  at 80.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:36] {2853} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:36] {3036} INFO -  at 80.5s,\testimator xgboost's best error=0.1275,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:36] {2853} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:36] {3036} INFO -  at 80.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:36] {2853} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:36] {3036} INFO -  at 81.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:37] {2853} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:37] {3036} INFO -  at 81.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:37] {2853} INFO - iteration 142, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:37] {3036} INFO -  at 81.7s,\testimator xgboost's best error=0.1225,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:37] {2853} INFO - iteration 143, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:38] {3036} INFO -  at 82.2s,\testimator xgboost's best error=0.1225,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:38] {2853} INFO - iteration 144, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:38] {3036} INFO -  at 82.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:38] {2853} INFO - iteration 145, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:38] {3036} INFO -  at 82.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:38] {2853} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:38] {3036} INFO -  at 83.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:38] {2853} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:39] {3036} INFO -  at 83.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:39] {2853} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:39] {3036} INFO -  at 83.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:39] {2853} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:39] {3036} INFO -  at 83.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:39] {2853} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:39] {3036} INFO -  at 83.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:39] {2853} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 06-12 11:52:41] {3036} INFO -  at 85.1s,\testimator rf's best error=0.1861,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:41] {2853} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:41] {3036} INFO -  at 85.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:41] {2853} INFO - iteration 153, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:41] {3036} INFO -  at 85.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:41] {2853} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:41] {3036} INFO -  at 85.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:41] {2853} INFO - iteration 155, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:42] {3036} INFO -  at 86.2s,\testimator xgboost's best error=0.1225,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:42] {2853} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:42] {3036} INFO -  at 86.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:42] {2853} INFO - iteration 157, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:42] {3036} INFO -  at 86.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:42] {2853} INFO - iteration 158, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:43] {3036} INFO -  at 87.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:43] {2853} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:43] {3036} INFO -  at 87.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:43] {2853} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:43] {3036} INFO -  at 87.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:43] {2853} INFO - iteration 161, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:43] {3036} INFO -  at 87.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:43] {2853} INFO - iteration 162, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:45] {3036} INFO -  at 89.2s,\testimator extra_tree's best error=0.1361,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:45] {2853} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:45] {3036} INFO -  at 89.5s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:45] {2853} INFO - iteration 164, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:45] {3036} INFO -  at 89.9s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:45] {2853} INFO - iteration 165, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:46] {3036} INFO -  at 90.2s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:46] {2853} INFO - iteration 166, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:46] {3036} INFO -  at 90.5s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:46] {2853} INFO - iteration 167, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:46] {3036} INFO -  at 90.9s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:46] {2853} INFO - iteration 168, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:47] {3036} INFO -  at 91.1s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:47] {2853} INFO - iteration 169, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:47] {3036} INFO -  at 91.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:47] {2853} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:47] {3036} INFO -  at 91.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:47] {2853} INFO - iteration 171, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:48] {3036} INFO -  at 92.1s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:48] {2853} INFO - iteration 172, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:48] {3036} INFO -  at 92.6s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:48] {2853} INFO - iteration 173, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:48] {3036} INFO -  at 92.9s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:48] {2853} INFO - iteration 174, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:49] {3036} INFO -  at 93.1s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:49] {2853} INFO - iteration 175, current learner extra_tree\n",
      "[flaml.automl: 06-12 11:52:50] {3036} INFO -  at 94.4s,\testimator extra_tree's best error=0.1361,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:50] {2853} INFO - iteration 176, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:50] {3036} INFO -  at 94.7s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:50] {2853} INFO - iteration 177, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:51] {3036} INFO -  at 95.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:51] {2853} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:51] {3036} INFO -  at 95.3s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:51] {2853} INFO - iteration 179, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:51] {3036} INFO -  at 95.7s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:51] {2853} INFO - iteration 180, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:52] {3036} INFO -  at 96.2s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:52] {2853} INFO - iteration 181, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:52] {3036} INFO -  at 96.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:52] {2853} INFO - iteration 182, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:52] {3036} INFO -  at 96.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:52] {2853} INFO - iteration 183, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:52] {3036} INFO -  at 97.0s,\testimator xgb_limitdepth's best error=0.1344,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:53] {2853} INFO - iteration 184, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:53] {3036} INFO -  at 97.4s,\testimator xgb_limitdepth's best error=0.1344,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:53] {2853} INFO - iteration 185, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:53] {3036} INFO -  at 97.8s,\testimator xgb_limitdepth's best error=0.0533,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:53] {2853} INFO - iteration 186, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:54] {3036} INFO -  at 98.2s,\testimator xgb_limitdepth's best error=0.0533,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:54] {2853} INFO - iteration 187, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:54] {3036} INFO -  at 98.6s,\testimator xgb_limitdepth's best error=0.0533,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:54] {2853} INFO - iteration 188, current learner xgboost\n",
      "[flaml.automl: 06-12 11:52:54] {3036} INFO -  at 98.9s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:54] {2853} INFO - iteration 189, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:55] {3036} INFO -  at 99.5s,\testimator xgb_limitdepth's best error=0.0533,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:55] {2853} INFO - iteration 190, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:55] {3036} INFO -  at 99.9s,\testimator xgb_limitdepth's best error=0.0533,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:55] {2853} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:56] {3036} INFO -  at 100.4s,\testimator xgb_limitdepth's best error=0.0533,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:56] {2853} INFO - iteration 192, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:56] {3036} INFO -  at 100.8s,\testimator xgb_limitdepth's best error=0.0533,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:56] {2853} INFO - iteration 193, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:57] {3036} INFO -  at 101.3s,\testimator xgb_limitdepth's best error=0.0533,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:57] {2853} INFO - iteration 194, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:57] {3036} INFO -  at 101.7s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:57] {2853} INFO - iteration 195, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:57] {3036} INFO -  at 101.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:57] {2853} INFO - iteration 196, current learner lgbm\n",
      "[flaml.automl: 06-12 11:52:58] {3036} INFO -  at 102.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:58] {2853} INFO - iteration 197, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:58] {3036} INFO -  at 102.6s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:58] {2853} INFO - iteration 198, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:59] {3036} INFO -  at 103.0s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:59] {2853} INFO - iteration 199, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:52:59] {3036} INFO -  at 103.5s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:52:59] {2853} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:00] {3036} INFO -  at 104.5s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:00] {2853} INFO - iteration 201, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:00] {3036} INFO -  at 104.7s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:00] {2853} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:00] {3036} INFO -  at 104.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:00] {2853} INFO - iteration 203, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:01] {3036} INFO -  at 105.2s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:01] {2853} INFO - iteration 204, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:01] {3036} INFO -  at 105.5s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:01] {2853} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:01] {3036} INFO -  at 106.0s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:01] {2853} INFO - iteration 206, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:02] {3036} INFO -  at 106.4s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:02] {2853} INFO - iteration 207, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:02] {3036} INFO -  at 106.7s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:02] {2853} INFO - iteration 208, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:03] {3036} INFO -  at 107.0s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:03] {2853} INFO - iteration 209, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:03] {3036} INFO -  at 107.5s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:03] {2853} INFO - iteration 210, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:03] {3036} INFO -  at 107.8s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:03] {2853} INFO - iteration 211, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:04] {3036} INFO -  at 108.2s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:04] {2853} INFO - iteration 212, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:04] {3036} INFO -  at 108.5s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:04] {2853} INFO - iteration 213, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:04] {3036} INFO -  at 109.0s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:04] {2853} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:05] {3036} INFO -  at 109.4s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:05] {2853} INFO - iteration 215, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:05] {3036} INFO -  at 109.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:05] {2853} INFO - iteration 216, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:06] {3036} INFO -  at 110.2s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:06] {2853} INFO - iteration 217, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:06] {3036} INFO -  at 110.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:06] {2853} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:07] {3036} INFO -  at 111.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:07] {2853} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:07] {3036} INFO -  at 111.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:07] {2853} INFO - iteration 220, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:07] {3036} INFO -  at 111.9s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:07] {2853} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:08] {3036} INFO -  at 112.6s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:08] {2853} INFO - iteration 222, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:09] {3036} INFO -  at 113.4s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:09] {2853} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:09] {3036} INFO -  at 113.8s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:09] {2853} INFO - iteration 224, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:09] {3036} INFO -  at 114.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:09] {2853} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:10] {3036} INFO -  at 114.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:10] {2853} INFO - iteration 226, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:10] {3036} INFO -  at 114.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:10] {2853} INFO - iteration 227, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:10] {3036} INFO -  at 114.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:10] {2853} INFO - iteration 228, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:11] {3036} INFO -  at 115.3s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:11] {2853} INFO - iteration 229, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:11] {3036} INFO -  at 115.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:11] {2853} INFO - iteration 230, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:12] {3036} INFO -  at 116.1s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:12] {2853} INFO - iteration 231, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:12] {3036} INFO -  at 116.7s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:12] {2853} INFO - iteration 232, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:13] {3036} INFO -  at 117.1s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:13] {2853} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:13] {3036} INFO -  at 117.5s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:13] {2853} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:13] {3036} INFO -  at 117.9s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:13] {2853} INFO - iteration 235, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:14] {3036} INFO -  at 118.4s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:14] {2853} INFO - iteration 236, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:14] {3036} INFO -  at 118.7s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:14] {2853} INFO - iteration 237, current learner xgb_limitdepth\n",
      "[flaml.automl: 06-12 11:53:15] {3036} INFO -  at 119.1s,\testimator xgb_limitdepth's best error=0.0461,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:15] {2853} INFO - iteration 238, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:15] {3036} INFO -  at 119.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:15] {2853} INFO - iteration 239, current learner xgboost\n",
      "[flaml.automl: 06-12 11:53:15] {3036} INFO -  at 119.8s,\testimator xgboost's best error=0.0925,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:15] {2853} INFO - iteration 240, current learner lgbm\n",
      "[flaml.automl: 06-12 11:53:16] {3036} INFO -  at 120.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
      "[flaml.automl: 06-12 11:53:16] {3292} INFO - retrain lgbm for 0.1s\n",
      "[flaml.automl: 06-12 11:53:16] {3297} INFO - retrained model: LGBMClassifier(colsample_bytree=0.7337732673006794, learning_rate=1.0,\n",
      "               max_bin=127, min_child_samples=3, n_estimators=8, num_leaves=11,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.0612978067806462,\n",
      "               verbose=-1)\n",
      "[flaml.automl: 06-12 11:53:16] {2592} INFO - fit succeeded\n",
      "[flaml.automl: 06-12 11:53:16] {2594} INFO - Time taken to find the best model: 48.19554924964905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7c58830c90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.lazy_morgan import MorganBinaryClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"SMILES\"], df[\"bin_act\"], test_size=0.2)\n",
    "\n",
    "mdl = MorganBinaryClassifier()\n",
    "mdl.fit(X_train, y_train)\n",
    "y_pred = mdl.predict_proba(X_test)\n",
    "\n",
    "\n",
    "fpr_test, tpr_test, _ = metrics.roc_curve(y_test, y_pred[:,1])\n",
    "auc_test = metrics.roc_auc_score(y_test, y_pred[:,1])\n",
    "\n",
    "plt.plot(fpr_test, tpr_test, label = str(auc_test), lw=2.5, color = \"#bee6b4\")\n",
    "plt.xlabel(\"False Positive Rate\", fontsize =14)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.title(\"ROC-AUC\", fontsize=16)\n",
    "plt.legend(loc = 'lower right')\n",
    "#plt.savefig(os.path.join(\"../figures\", \"roc_auto6.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl._auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1(C)Cc2c(C#N)c(nc(c2CO1)N1CCOCC1)SCC(=O)Nc1c...</td>\n",
       "      <td>D396-0181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(CBr)n1ncnn1</td>\n",
       "      <td>8009-0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCS(=O)(=O)N=C1NCN(CC(=O)[O-])CN1</td>\n",
       "      <td>5044-0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C[C@@]12CC[C@H](O)C[C@H]1[C@@H](O)CC1[C@H]2C[C...</td>\n",
       "      <td>N037-0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1[nH]c(=S)[nH]c(=O)c1CCCO</td>\n",
       "      <td>3399-0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300534</th>\n",
       "      <td>CCCCNC(=O)C1(CCC1)c1ccc(cc1)NS(=O)(=O)c1cc(OC)...</td>\n",
       "      <td>L426-0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300535</th>\n",
       "      <td>CCCCN(CC)c1ccc(cc1C(=O)O)NS(=O)(=O)c1cc(F)c(F)cc1</td>\n",
       "      <td>F294-0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300536</th>\n",
       "      <td>CN(C)CCN(CC)c1ccc(cc1NS(=O)(=O)c1ccc(C)cc1C)C(...</td>\n",
       "      <td>F295-0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300537</th>\n",
       "      <td>Nc1c(Br)cc(cc1Br)NS(=O)(=O)c1ccccc1</td>\n",
       "      <td>R052-1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300538</th>\n",
       "      <td>Cc1ccc(cc1)NS(=O)(=O)c1ccc(N)cc1</td>\n",
       "      <td>R004-0058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300539 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   smiles         id\n",
       "0       CC1(C)Cc2c(C#N)c(nc(c2CO1)N1CCOCC1)SCC(=O)Nc1c...  D396-0181\n",
       "1                                          CC(CBr)n1ncnn1  8009-0167\n",
       "2                     CCCCS(=O)(=O)N=C1NCN(CC(=O)[O-])CN1  5044-0010\n",
       "3       C[C@@]12CC[C@H](O)C[C@H]1[C@@H](O)CC1[C@H]2C[C...  N037-0036\n",
       "4                             Cc1[nH]c(=S)[nH]c(=O)c1CCCO  3399-0213\n",
       "...                                                   ...        ...\n",
       "300534  CCCCNC(=O)C1(CCC1)c1ccc(cc1)NS(=O)(=O)c1cc(OC)...  L426-0625\n",
       "300535  CCCCN(CC)c1ccc(cc1C(=O)O)NS(=O)(=O)c1cc(F)c(F)cc1  F294-0550\n",
       "300536  CN(C)CCN(CC)c1ccc(cc1NS(=O)(=O)c1ccc(C)cc1C)C(...  F295-0500\n",
       "300537                Nc1c(Br)cc(cc1Br)NS(=O)(=O)c1ccccc1  R052-1647\n",
       "300538                   Cc1ccc(cc1)NS(=O)(=O)c1ccc(N)cc1  R004-0058\n",
       "\n",
       "[300539 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter list of molecules for docking\n",
    "smiles = pd.read_csv(\"../data/docking/full_lib/smiles.smi\", sep='\\t', names=['smiles', 'id'])\n",
    "smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5ba2f1452682855ccf4135cb16ab3fe285c3388d1e3e2e119f7a866d80e2677"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('chemistry')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
